{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d157e33c",
   "metadata": {},
   "source": [
    "\n",
    "# Face Recognition under Varying Visual Conditions üß†üì∏\n",
    "**Author:** Third Year ML Enthusiast  \n",
    "**Task:** Robust Face Identity Prediction under diverse environmental conditions (fog, blur, glare, etc.) using MobileNetV2 and Test-Time Augmentation (TTA).  \n",
    "**Libraries:** TensorFlow, Keras, OpenCV, Seaborn, sklearn\n",
    "\n",
    "---\n",
    "\n",
    "### üìù Workflow Summary:\n",
    "1. Load dataset using ImageDataGenerator with real-time augmentation.\n",
    "2. Build and train a MobileNetV2-based model.\n",
    "3. Fine-tune the model with last few layers unfreezed.\n",
    "4. Evaluate performance globally and under specific visual distortions.\n",
    "5. Predict with TTA + CLAHE enhancement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e7e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install -q scikit-learn seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e876dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "from PIL import Image, ImageEnhance\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46145cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for mounting\n",
    "# from google.colab import drive\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "#defining the paths of train and test folder\n",
    "# zip_path = \"/content/drive/MyDrive/Colab Notebooks/Comys_Hackathon5.zip\"\n",
    "# extract_path = \"/content/drive/MyDrive/Comys_Hackathon5\"\n",
    "\n",
    "# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "#     zip_ref.extractall(extract_path)\n",
    "\n",
    "# Path to training data stored on Google Drive\n",
    "base_dir = '/content/drive/MyDrive/Comys_Hackathon5/Comys_Hackathon5/Task_B/train'\n",
    "\n",
    "# Image and training configurations\n",
    "IMAGE_SIZE = (160, 160)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a290b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training & validation data generators with augmentation and preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.5, 1.5],\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.15\n",
    ")\n",
    "\n",
    "# Load training set\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Load validation set\n",
    "val_gen = train_datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "NUM_CLASSES = train_gen.num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b910ce9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load MobileNetV2 (pretrained on ImageNet) without top layers\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(160, 160, 3))\n",
    "base_model.trainable = False  # Freeze base model\n",
    "\n",
    "# Add custom classification head\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07668a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Callbacks for saving best model and early stopping\n",
    "checkpoint = ModelCheckpoint(\"initial_model.h5\", monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Initial training\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[checkpoint, earlystop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014fb4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Unfreeze last 30 layers for fine-tuning\n",
    "for layer in base_model.layers[-30:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile with lower learning rate\n",
    "model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune\n",
    "fine_tune_history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=5,\n",
    "    callbacks=[earlystop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86312ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load trained model and prepare mapping\n",
    "model = load_model(\"initial_model.h5\")\n",
    "idx_to_class = {v: k for k, v in train_gen.class_indices.items()}\n",
    "\n",
    "# Enhance image using CLAHE (improves visibility under low-light, fog etc.)\n",
    "def enhance_image_clahe(img):\n",
    "    img = np.array(img)\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0)\n",
    "    cl = clahe.apply(l)\n",
    "    limg = cv2.merge((cl, a, b))\n",
    "    return cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "# Predict with TTA + CLAHE\n",
    "def predict_face_identity(image_path, confidence_threshold=0.5):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img = Image.fromarray(enhance_image_clahe(img)).resize((160, 160))\n",
    "\n",
    "    # Variants: original, flipped, brightness adjusted\n",
    "    variants = [\n",
    "        img,\n",
    "        img.transpose(Image.FLIP_LEFT_RIGHT),\n",
    "        ImageEnhance.Brightness(img).enhance(0.7),\n",
    "        ImageEnhance.Brightness(img).enhance(1.3)\n",
    "    ]\n",
    "\n",
    "    predictions = []\n",
    "    for var in variants:\n",
    "        arr = img_to_array(var)\n",
    "        arr = preprocess_input(arr)\n",
    "        arr = np.expand_dims(arr, axis=0)\n",
    "        pred = model.predict(arr)\n",
    "        predictions.append(pred)\n",
    "\n",
    "    avg_pred = np.mean(predictions, axis=0)\n",
    "    pred_index = np.argmax(avg_pred)\n",
    "    confidence = avg_pred[0][pred_index]\n",
    "    predicted_class = idx_to_class[pred_index]\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Prediction: {predicted_class}\\nConfidence: {confidence:.2f}\")\n",
    "    plt.show()\n",
    "\n",
    "    if confidence < confidence_threshold:\n",
    "        print(\"Low confidence prediction ‚Äî may be inaccurate.\")\n",
    "\n",
    "    return predicted_class, confidence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3857afb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_gen.reset()\n",
    "preds = model.predict(val_gen, verbose=1)\n",
    "y_true = val_gen.classes\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "\n",
    "# Metrics\n",
    "top1_acc = accuracy_score(y_true, y_pred)\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "print(f\"Top-1 Accuracy: {top1_acc:.4f}\")\n",
    "print(f\"Macro F1 Score: {f1_macro:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cm, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b46d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filenames = val_gen.filenames\n",
    "idx_to_class = {v: k for k, v in val_gen.class_indices.items()}\n",
    "\n",
    "def get_condition(fname):\n",
    "    fname = fname.lower()\n",
    "    for cond in ['blur', 'fog', 'rain', 'low', 'over', 'sun', 'glare', 'light']:\n",
    "        if cond in fname:\n",
    "            return cond\n",
    "    return 'normal'\n",
    "\n",
    "conditions = [get_condition(f) for f in filenames]\n",
    "cond_perf = {}\n",
    "\n",
    "# Group results by condition type\n",
    "for i, cond in enumerate(conditions):\n",
    "    if cond not in cond_perf:\n",
    "        cond_perf[cond] = {'y_true': [], 'y_pred': []}\n",
    "    cond_perf[cond]['y_true'].append(y_true[i])\n",
    "    cond_perf[cond]['y_pred'].append(y_pred[i])\n",
    "\n",
    "print(\"\\nPerformance by Visual Condition:\")\n",
    "for cond, val in cond_perf.items():\n",
    "    acc = accuracy_score(val['y_true'], val['y_pred'])\n",
    "    f1 = f1_score(val['y_true'], val['y_pred'], average='macro')\n",
    "    print(f\"{cond.capitalize():<12} | Accuracy: {acc:.4f} | Macro F1: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb63a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize training + fine-tuning progress\n",
    "def plot_training(history, fine_tune_history):\n",
    "    acc = history.history['accuracy'] + fine_tune_history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy'] + fine_tune_history.history['val_accuracy']\n",
    "    loss = history.history['loss'] + fine_tune_history.history['loss']\n",
    "    val_loss = history.history['val_loss'] + fine_tune_history.history['val_loss']\n",
    "\n",
    "    epochs_range = range(len(acc))\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, acc, label='Train Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Val Accuracy')\n",
    "    plt.title('Accuracy Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Train Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Val Loss')\n",
    "    plt.title('Loss Over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call plot function\n",
    "plot_training(history, fine_tune_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56587681",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict on a sample image\n",
    "image_path = '/content/drive/MyDrive/Comys_Hackathon5/Comys_Hackathon5/Task_B/train/001_frontal/blur_face1.jpg'\n",
    "\n",
    "label, confidence = predict_face_identity(image_path)\n",
    "print(f\"Predicted Identity: {label} | Confidence: {confidence:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
